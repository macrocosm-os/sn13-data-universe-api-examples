# Gravity Jobs
Async / Offline dataset collection jobs that run in a few steps:

1. Define Crawler "Criteria" (platform & filters) and wait for data acquisition (miners collect and upload data)
2. Trigger a build after you have enough data
3. Download your dataset(s)

This behaviour is identical to how our UI works on the [constellation platform](https://app.macrocosmos.ai/gravity/tasks), just imitated through the API.

If it's your first time using Macrocosmos products, we strongly suggest going through the flow in the UI first, to get familiar.
